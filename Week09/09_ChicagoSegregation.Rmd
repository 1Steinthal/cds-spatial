---
title: "Spatial Segregation: Chicago Crime continued"
author: "Adela Sobotkova"
date: "24 March 2022 updated `r format(Sys.time(), '%B %d, %Y')`"
output: 
  html_document:
    toc: true
    toc_float: true
    highlight: tango
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r guideNOwosad}
# Spatial segregation on raster data (each race on separate raster)
# https://www.r-bloggers.com/2020/08/how-to-measure-spatial-diversity-and-segregation/
# Spatial segregation measures illustrated
# https://sejdemyr.github.io/r-tutorials/statistics/measuring-segregation.html
```


# Task 1: Bandwidth selection
We can get a more principled measure of the violent crime ratio using a spatial segregation model. The `spatialkernel` package implements the theory of spatial segregation (Reardon and O'Sullivan 2004).

The first step is to compute the optimal bandwidth for kernel smoothing under the segregation model. A small bandwidth would result in a density that is mostly zero, with spikes at the event locations. A large bandwidth would flatten out any structure in the events, resulting in a large "blob" across the whole window. Somewhere between these extremes is a bandwidth that best represents an underlying density for the process.

`spseg()` will scan over a range of bandwidths and compute a test statistic using a cross-validation method. The bandwidth that maximizes this test statistic is the one to use. The returned value from `spseg()` in this case is a list, with `h` and `cv` elements giving the values of the statistic over the input `h` values. The `spatialkernel` package supplies a `plotcv` function to show how the test value varies. The `hcv` element has the value of the best bandwidth. For more information, see [link](https://rdrr.io/cran/seg/man/spseg.html)

## Instructions

* Install `spatialkernel` package from Github. 
* Ensure that `spatstat` is loaded and the `chicago_crime` object is read in (check last tutorial). 
* Set `h`, the bandwidth values to try, then call `spseg(`).
 - You need to provide the start value, 500, then end value, 1000, and the step size, 50.
 - Assign the result to `bw_choice`.
* Plot the test statistic vs. the bandwidth.
 - Call `plotcv()` on `bw_choice`.
 - Highlight the best bandwidth by adding a vertical line where the test statistic is maximized. 

```{r bandwidth-exercise, eval = FALSE}
# Install spatialkernel (the CRAN version is outdated, so you need to grab the most recent maintained version from Github). You may need to install.packages("devtools") and then run:
devtools::install_github("becarioprecario/spatialkernel")

# Libraries
library(spatstat)
library(spatialkernel)

# Data
chicago_crime <- ________("data/crimeCH-spatstat.rds")

# Scan from 500m to 1000m in steps of 50m
bw_choice <- spseg(
    chicago_crime, 
    h = seq(___, ___, by = ___),
    opt = 1)

# Plot the results and highlight the best bandwidth
plotcv(bw_choice); abline(v = bw_choice$___, lty = 2, col = "red")

# Print the best bandwidth
print(bw_choice$___)
```

### Solution  

```{r bandwidth-sol, echo=FALSE}
# Library
library(spatstat)
library(spatialkernel)

# Data
#chicago_crime <- readRDS("../data/crimeCH-spatstat.rds")
# crime_violent <- readRDS("../data/crime_violent.rds")

# Create a round window around Hilton Hotel (or roughly downtown)

# Find mean center (or choose a location)
xy <- st_coordinates(crimeCH)
mc <- apply(xy, 2, mean)
mc <- cbind(mc[1]+ 5000,mc[2]-10000)   
# standard distance
sd <- sqrt(sum((xy[,1] - mc[1])^2 + (xy[,2] - mc[2])^2) / nrow(xy))

# Plot the available data
plot(city$geometry, col='light blue')
#points(st_geometry(crimeCH), cex=.5)
points(cbind(mc[1], mc[2]), pch='*', col='red', cex=5)

# Make a circle
bearing <- 1:360 * pi/180
cx <- mc[1] + sd * cos(bearing)
cy <- mc[2] + sd * sin(bearing)
circle <- cbind(cx, cy)
plot(city$geometry, col='light blue')
points(cbind(mc[1], mc[2]), pch='*', col='red', cex=5)
lines(circle, col='red', lwd=2)

plot(city$geometry, col='light blue'); plot(d, add = T)
d <- disc(radius =13000, centre = mc )

d <- st_cast(d, "POLYGON")
```

# Crop points
```{r}
# Bind the circle points and cast as a polygon
library(tidyverse)
c <- as.data.frame(circle) %>%
  st_as_sf(coords = c("cx", "cy"), crs = 26916) %>%  # UTM 16 USA
  summarise(geometry = st_combine(geometry)) %>%  # concatenating points in order to make a polygon
  st_cast("POLYGON")  # make polygon out of the points
library(mapview)
c %>% mapview() 

cwindow <- as.owin(c)

# Use the circle to clip crimes
crime_p <- crime_v %>% 
  st_intersection(c) 

crime_violent <- as.ppp(st_coordinates(crime_p), W = d)
marks(crime_violent) = as.factor(crime_p$crimetype)
plot(split(crime_violent))
```

# Find the best bandwidth
```{r bandwidth-sol, echo=FALSE}
# Scan from 500m to 1000m in steps of 50m
?spseg()
bw_choice <- spseg(
    crime_violent, 
    h = seq(500,1000, by = 50),
    opt = 1)

# Getting an Error: 'as.polygonal' is not an exported object from 'namespace:spatstat'? 
# Try : https://stackoverflow.com/questions/66674391/why-does-asspdf-owin-throw-an-error-spatstat-options-is-not-an-exported-o
update.packages(ask = FALSE)
bw_choice
# Plot the results and highlight the best bandwidth
plotcv(bw_choice); abline(v = bw_choice$hcv, lty = 2, col = "red")

# Print the best bandwidth
print(bw_choice$hcv)
```

Amazing! Now you know the optimal smoothing parameter, you can do some kernel smoothing simulations.

# Task 2:  Segregation probabilities
The second step is to compute the probabilities for violent and non-violent crimes as a smooth surface, as well as the p-values for a point-wise test of segregation. This is done by calling `spseg()` with `opt = 3` and a fixed bandwidth parameter `h`.

Normally you would run this process for at least 100 simulations, but that will take too long to run here. Instead, run for only 10 simulations. Then you can use a saved object `seg` which is the output from a 1000 simulation run that took about 20 minutes to complete.

## Instructions

* Ensure the `chicago_crime` points data is loaded. 
* You can also get the optimum bandwidth from the `hcv` element of `bw_choice`.
 - Set the bandwidth parameter h.
 - Run the function for 10 simulations only via the `ntest` parameter.
 - The output consists of probability maps for each class in the marks of the data. Plot the map for the violent crimes. Add "Violent crime" as the title to your plots. 

```{r optimum-bandwith, eval=FALSE}
# Set the correct bandwidth and run for 10 simulations only
seg10 <- spseg(
    pts = chicago_crime, 
    h = ___,
    opt = 3,
    ntest = ___, 
    proc = FALSE)
# Plot the segregation map for violent crime
plotmc(seg10, "___")

# Modify the script above to run 1000 simulations and write the result to 'seg'. 
# Plot seg, the result of running 1000 simulations
plotmc(seg, "___")

```

### Solution
```{r opt-bandwidh, echo=FALSE}
# Set the correct bandwidth and run for 10 simulations only
seg10 <- spseg(
    pts = chicago_crime, 
    h = 800,
    opt = 3,
    ntest = 10, 
    proc = FALSE)
# Plot the segregation map for violent crime
plotmc(seg10, "Violent crime")

# Try to run 1000 simulations and write the result to 'seg' if you wish to take 15+ minutes break. Alternatively read in the seg.rds object from data using the readRDS() function
seg <- readRDS("data/seg.rds")
# seg <- spseg(
#     pts = chicago_crime, 
#     h = 800,
#     opt = 3,
#     ntest = 1000, 
#     proc = FALSE)
# library(tidyverse)
# write_rds(seg, "data/seg.rds", compress="none")

# Plot seg, the result of running 1000 simulations
plotmc(seg, "Violent crime")

```

Good work! The simulation shows that crime is relatively more violent in the town centre and South Western edge.

# Task 3: Mapping segregation

With a base map and some image and contour functions we can display both the probabilities and the significance tests over the area with more control than the `plotmc()` function.

The `seg` object is a list with several components. The X and Y coordinates of the grid are stored in the `$gridx` and `$gridy` elements. The probabilities of each class of data (violent or non-violent crime) are in a matrix element `$p` with a column for each class. The p-value of the significance test is in a similar matrix element called `$stpvalue`. Rearranging columns of these matrices into a grid of values can be done with R's matrix() function. From there you can construct list objects with a vector `$x` of X-coordinates, `$y` of Y-coordinates, and `$z` as the matrix. You can then feed this to `image()` or `contour()` for visualization.

This process may seem complex, but remember that with R you can always write functions to perform complex tasks and those you may repeat often. For example, to help with the mapping in this exercise you will create a function that builds a map from four different items.

The `seg` object from 1000 simulations is loaded, as well as the `chicago_crime` points and the `preston_osm` map image.

## Instructions

* Inspect the segregation object. 
  - Use `str()` to see the structure of `seg`. 
  - Set `ncol` as the length of one of the elements of `seg`.
* Create prob_violent as a list with 
  - x as the gridx element of `seg`. 
  - y as the gridy element. 
  - z as a matrix with the "violent crime" column of the p element.
* Create `p_value` as in the previous step, except that the `z` element is logical, and `TRUE` when the `stpvalue` element of seg is less than 0.05.
* Call the `segmap()` function shown in the script to find areas where the probability of a crime being violent is above 0.15. Use 0.05 as the lower probability.

```{r segregation, eval=FALSE}
# Inspect the structure of the spatial segregation object
str(___)

# Get the number of columns in the data so we can rearrange to a grid
ncol <- length(seg$___)

# Rearrange the probability column into a grid
prob_violent <- list(x = seg$___,
                     y = seg$___,
                     z = matrix(seg$___[, "Violent crime"],
                                ncol = ncol))
image(prob_violent)

p_value <- list(x = seg$___,
                y = seg$___,
                z = matrix(seg$___[, "Violent crime"]< 0.05,
                                ncol = ncol))
image(p_value)


# Create a mapping function
segmap <- function(prob_list, pv_list, low, high){

  # background map
  library(raster)
  preston_osm <- ______("data/osm_preston_gray.rds")
  plotRGB(preston_osm)

  # p-value areas
  image(pv_list, 
        col = c("#00000000", "#FF808080"), add = TRUE) 

  # probability contours
  contour(prob_list,
          levels = c(low, high),
          col = c("#206020", "red"),
          labels = c("Low", "High"),
          add = TRUE)

  # boundary window
  plot(Window(chicago_crime), add = TRUE)
}

# Map the probability and p-value
segmap(prob_violent, p_value, ___, ___)
```


### Solution
```{r segr-sol, echo=FALSE}
# Inspect the structure of the spatial segregation object
str(seg)

# Get the number of columns in the data so we can rearrange to a grid
ncol <- length(seg$gridx)

# Rearrange the probability column into a grid
prob_violent <- list(x = seg$gridx,
                     y = seg$gridy,
                     z = matrix(seg$p[, "Violent crime"],
                                ncol = ncol))
image(prob_violent) # this georeferences the image within original coordinates!!! IMPORTANT


# Rearrange the p-values, but choose a p-value threshold
p_value <- list(x = seg$gridx,
                y = seg$gridy,
                z = matrix(seg$stpvalue[, "Violent crime"] < 0.05,
                           ncol = ncol))
image(p_value)


# Create a mapping function
segmap <- function(prob_list, pv_list, low, high){

  # background map
  library(raster)
  preston_osm <- readRDS("data/osm_preston_gray.rds")
  plotRGB(preston_osm)

  # p-value areas
  image(pv_list, 
        col = c("#00000000", "#FF808080"), add = TRUE) 

  # probability contours
  contour(prob_list,
          levels = c(low, high),
          col = c("#206020", "red"),
          labels = c("Low", "High"),
          add = TRUE)

  # boundary window
  plot(Window(chicago_crime), add = TRUE)
}

# Map the probability and p-value
segmap(prob_violent, p_value, 0.05, 0.15)


```

Great work! By displaying the violent crime areas on the map, it's really easy to understand where the problem areas are.

